{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0000001",
   "metadata": {},
   "source": [
    "# CellOracle GRN Calculation - Per Cell Type\n",
    "Loop through each cell type in `cluster_annot`, subset data, and build GRNs using `sample` as the cluster unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000002",
   "metadata": {},
   "source": [
    "## 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "\n",
    "import celloracle as co\n",
    "co.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4.5]\n",
    "plt.rcParams[\"savefig.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000005",
   "metadata": {},
   "source": [
    "## 1. Load full dataset and base GRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full data\n",
    "adata_full = sc.read_h5ad(\"CTR9_snRNASeq/CTR9_snRNASeq_full.h5ad\")\n",
    "print(f\"Loaded data: {adata_full.shape[0]} cells x {adata_full.shape[1]} genes\")\n",
    "print(f\"\\nCell types (cluster_annot): {adata_full.obs['cluster_annot'].unique().tolist()}\")\n",
    "print(f\"Samples: {adata_full.obs['sample'].unique().tolist()}\")\n",
    "adata_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base GRN once (shared across all cell types)\n",
    "base_GRN = co.data.load_mouse_scATAC_atlas_base_GRN()\n",
    "print(f\"Base GRN shape: {base_GRN.shape}\")\n",
    "base_GRN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all cell types\n",
    "cell_types = adata_full.obs['cluster_annot'].unique().tolist()\n",
    "print(f\"Will process {len(cell_types)} cell types:\")\n",
    "for i, ct in enumerate(cell_types):\n",
    "    n_cells = (adata_full.obs['cluster_annot'] == ct).sum()\n",
    "    print(f\"  {i}: {ct} ({n_cells} cells)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000009",
   "metadata": {},
   "source": [
    "## 2. Create output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base output directories\n",
    "base_results = \"celloracle_results/per_celltype\"\n",
    "base_figures = \"celltype_figures\"\n",
    "base_genes = \"celltype_genes\"\n",
    "\n",
    "os.makedirs(base_results, exist_ok=True)\n",
    "os.makedirs(base_figures, exist_ok=True)\n",
    "os.makedirs(base_genes, exist_ok=True)\n",
    "print(\"\\u2713 Base directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000011",
   "metadata": {},
   "source": [
    "## 3. Define the per-cell-type pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_celloracle_for_celltype(adata_full, cell_type, base_GRN,\n",
    "                                 base_results, base_figures, base_genes,\n",
    "                                 min_cells=50, n_top_genes=3000):\n",
    "    \"\"\"\n",
    "    Run the full CellOracle pipeline for a single cell type.\n",
    "    GRN is built using 'sample' as the cluster unit (WT vs KO comparison).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adata_full : AnnData\n",
    "        Full dataset\n",
    "    cell_type : str\n",
    "        Cell type to subset from cluster_annot\n",
    "    base_GRN : pd.DataFrame\n",
    "        Base GRN from CellOracle\n",
    "    min_cells : int\n",
    "        Minimum number of cells required to run pipeline\n",
    "    n_top_genes : int\n",
    "        Number of highly variable genes to select\n",
    "    \"\"\"\n",
    "    # Safe name for file paths\n",
    "    safe_name = cell_type.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\" \", \"_\")\n",
    "    \n",
    "    # Create cell-type-specific directories\n",
    "    save_folder = f\"{base_figures}/{safe_name}\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    os.makedirs(f\"{save_folder}/degree_distribution\", exist_ok=True)\n",
    "    os.makedirs(f\"{save_folder}/ranked_score\", exist_ok=True)\n",
    "    os.makedirs(f\"{save_folder}/score_comparison\", exist_ok=True)\n",
    "    os.makedirs(f\"{save_folder}/top30_degree_centrality\", exist_ok=True)\n",
    "    os.makedirs(f\"{base_genes}/{safe_name}\", exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Processing: {cell_type}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 1. Subset to this cell type\n",
    "    # =========================================================\n",
    "    adata = adata_full[adata_full.obs['cluster_annot'] == cell_type, :].copy()\n",
    "    print(f\"\\n[1] Subset: {adata.shape[0]} cells x {adata.shape[1]} genes\")\n",
    "    \n",
    "    # Check minimum cell count\n",
    "    if adata.shape[0] < min_cells:\n",
    "        print(f\"  ⚠ Skipping {cell_type}: only {adata.shape[0]} cells (min={min_cells})\")\n",
    "        return None, None\n",
    "    \n",
    "    # Check sample distribution\n",
    "    sample_counts = adata.obs['sample'].value_counts()\n",
    "    print(f\"  Sample distribution:\")\n",
    "    for s, c in sample_counts.items():\n",
    "        print(f\"    {s}: {c} cells\")\n",
    "    \n",
    "    if len(sample_counts) < 2:\n",
    "        print(f\"  ⚠ Skipping {cell_type}: only 1 sample present\")\n",
    "        return None, None\n",
    "    \n",
    "    # =========================================================\n",
    "    # 2. Preprocessing\n",
    "    # =========================================================\n",
    "    print(f\"\\n[2] Preprocessing...\")\n",
    "    \n",
    "    # Save raw counts to layers\n",
    "    if hasattr(adata, 'raw') and adata.raw is not None:\n",
    "        adata.layers['counts'] = adata.raw.X.copy()\n",
    "        adata.layers['log1p'] = adata.X.copy()\n",
    "    else:\n",
    "        adata.layers['counts'] = adata.X.copy()\n",
    "    \n",
    "    # Filter genes\n",
    "    sc.pp.filter_genes(adata, min_counts=1)\n",
    "    print(f\"  After gene filtering: {adata.shape}\")\n",
    "    \n",
    "    # Normalize\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    \n",
    "    # Select HVGs - adjust n_top_genes if we have fewer genes\n",
    "    actual_n_top = min(n_top_genes, adata.shape[1] - 1)\n",
    "    filter_result = sc.pp.filter_genes_dispersion(\n",
    "        adata.X,\n",
    "        flavor='cell_ranger',\n",
    "        n_top_genes=actual_n_top,\n",
    "        log=False\n",
    "    )\n",
    "    print(f\"  Selected {filter_result.gene_subset.sum()} highly variable genes\")\n",
    "    \n",
    "    adata = adata[:, filter_result.gene_subset]\n",
    "    \n",
    "    # Renormalize\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    print(f\"  After HVG selection: {adata.shape}\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 3. Compute embeddings\n",
    "    # =========================================================\n",
    "    print(f\"\\n[3] Computing embeddings...\")\n",
    "    \n",
    "    if 'X_pca' not in adata.obsm.keys():\n",
    "        sc.pp.pca(adata, n_comps=min(50, adata.shape[0] - 1, adata.shape[1] - 1))\n",
    "    print(f\"  \\u2713 PCA\")\n",
    "    \n",
    "    n_neighbors = min(30, adata.shape[0] - 1)\n",
    "    sc.pp.neighbors(adata, n_pcs=min(30, adata.obsm['X_pca'].shape[1]), n_neighbors=n_neighbors)\n",
    "    print(f\"  \\u2713 Neighbors (n={n_neighbors})\")\n",
    "    \n",
    "    sc.tl.umap(adata)\n",
    "    print(f\"  \\u2713 UMAP\")\n",
    "    \n",
    "    # Save UMAP plot\n",
    "    sc.pl.umap(adata, color='sample', title=f\"{cell_type} - by sample\", show=False)\n",
    "    plt.savefig(f\"{save_folder}/umap_by_sample.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4. Create Oracle object\n",
    "    # =========================================================\n",
    "    print(f\"\\n[4] Creating Oracle object...\")\n",
    "    \n",
    "    oracle = co.Oracle()\n",
    "    \n",
    "    # Import data - use 'sample' as cluster column for WT vs KO GRN building\n",
    "    oracle.import_anndata_as_raw_count(\n",
    "        adata=adata,\n",
    "        cluster_column_name=\"sample\",\n",
    "        embedding_name=\"X_umap\"\n",
    "    )\n",
    "    print(f\"  \\u2713 Data imported (cluster_column='sample')\")\n",
    "    \n",
    "    # Import TF info\n",
    "    oracle.import_TF_data(TF_info_matrix=base_GRN)\n",
    "    print(f\"  \\u2713 TF data imported\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 5. KNN imputation\n",
    "    # =========================================================\n",
    "    print(f\"\\n[5] KNN imputation...\")\n",
    "    \n",
    "    oracle.perform_PCA()\n",
    "    \n",
    "    # Select n_comps\n",
    "    try:\n",
    "        n_comps = np.where(\n",
    "            np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_)) > 0.002)\n",
    "        )[0][0]\n",
    "    except IndexError:\n",
    "        n_comps = min(20, oracle.adata.shape[0] - 1)\n",
    "    n_comps = max(n_comps, 5)  # Ensure at least 5 components\n",
    "    print(f\"  PCA components: {n_comps}\")\n",
    "    \n",
    "    n_cell = oracle.adata.shape[0]\n",
    "    k = max(int(0.025 * n_cell), 5)  # Ensure k >= 5\n",
    "    print(f\"  Cell count: {n_cell}, k: {k}\")\n",
    "    \n",
    "    oracle.knn_imputation(\n",
    "        n_pca_dims=n_comps,\n",
    "        k=k,\n",
    "        balanced=True,\n",
    "        b_sight=k * 8,\n",
    "        b_maxl=k * 4,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    print(f\"  \\u2713 KNN imputation complete\")\n",
    "    \n",
    "    # Save oracle object\n",
    "    oracle_path = f\"{base_results}/{safe_name}.celloracle.oracle\"\n",
    "    oracle.to_hdf5(oracle_path)\n",
    "    print(f\"  \\u2713 Oracle saved: {oracle_path}\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 6. GRN calculation (using 'sample' as cluster unit)\n",
    "    # =========================================================\n",
    "    print(f\"\\n[6] GRN calculation (by sample)...\")\n",
    "    \n",
    "    links = oracle.get_links(\n",
    "        cluster_name_for_GRN_unit=\"sample\",\n",
    "        alpha=10,\n",
    "        verbose_level=10\n",
    "    )\n",
    "    \n",
    "    # Save raw links\n",
    "    links_path = f\"{base_results}/{safe_name}.celloracle.links\"\n",
    "    links.to_hdf5(file_path=links_path)\n",
    "    print(f\"  \\u2713 Links saved: {links_path}\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 7. Network preprocessing\n",
    "    # =========================================================\n",
    "    print(f\"\\n[7] Network preprocessing...\")\n",
    "    \n",
    "    links.filter_links(p=0.001, weight=\"coef_abs\", threshold_number=2000)\n",
    "    print(f\"  \\u2713 Links filtered\")\n",
    "    \n",
    "    # Degree distribution plots\n",
    "    for cluster in links.cluster:\n",
    "        safe_cluster = cluster.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "        cluster_folder = f\"{save_folder}/degree_distribution/degree_dist_{safe_cluster}\"\n",
    "        os.makedirs(cluster_folder, exist_ok=True)\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [9, 4.5]\n",
    "    links.plot_degree_distributions(\n",
    "        plot_model=True,\n",
    "        save=f\"{save_folder}/degree_distribution/\"\n",
    "    )\n",
    "    plt.rcParams[\"figure.figsize\"] = [6, 4.5]\n",
    "    \n",
    "    # =========================================================\n",
    "    # 8. Network scores\n",
    "    # =========================================================\n",
    "    print(f\"\\n[8] Calculating network scores...\")\n",
    "    \n",
    "    links.get_network_score()\n",
    "    print(f\"  \\u2713 Network scores calculated\")\n",
    "    \n",
    "    # Save filtered + scored links\n",
    "    filtered_links_path = f\"{base_results}/{safe_name}_filtered.celloracle.links\"\n",
    "    links.to_hdf5(file_path=filtered_links_path)\n",
    "    print(f\"  \\u2713 Filtered links saved: {filtered_links_path}\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 9. Save gene scores\n",
    "    # =========================================================\n",
    "    print(f\"\\n[9] Saving gene scores...\")\n",
    "    \n",
    "    merged_scores = links.merged_score\n",
    "    for clust in links.cluster:\n",
    "        safe_cluster = clust.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "        filepath = f\"{base_genes}/{safe_name}/{safe_cluster}_all_genes.csv\"\n",
    "        scores = merged_scores.loc[merged_scores['cluster'] == clust]\n",
    "        scores_sorted = scores.sort_values('degree_centrality_all', ascending=False)\n",
    "        scores_sorted.to_csv(filepath)\n",
    "        print(f\"  \\u2713 Saved: {filepath}\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 10. Visualize top genes with high degree centrality\n",
    "    # =========================================================\n",
    "    print(f\"\\n[10] Visualizing top genes...\")\n",
    "    \n",
    "    all_top_genes = []\n",
    "    for sample_name in links.cluster:\n",
    "        df = links.merged_score[links.merged_score[\"cluster\"] == sample_name].copy()\n",
    "        df_sorted = df.sort_values(\"degree_centrality_all\", ascending=False).head(50)\n",
    "        \n",
    "        # Collect top genes\n",
    "        df_top = df_sorted[[\"degree_centrality_all\"]].copy()\n",
    "        df_top[\"sample\"] = sample_name\n",
    "        df_top[\"cell_type\"] = cell_type\n",
    "        df_top[\"gene\"] = df_top.index\n",
    "        df_top[\"rank\"] = range(1, len(df_top) + 1)\n",
    "        all_top_genes.append(df_top)\n",
    "        \n",
    "        # Plot top 30\n",
    "        df_plot = df_sorted.head(30)\n",
    "        fig, ax = plt.subplots(figsize=(6, 8))\n",
    "        ax.scatter(df_plot[\"degree_centrality_all\"].values, range(len(df_plot)))\n",
    "        ax.set_yticks(range(len(df_plot)))\n",
    "        ax.set_yticklabels(df_plot.index)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(\"degree_centrality_all\")\n",
    "        ax.set_title(f\"degree_centrality_all\\ntop 30 in {cell_type} - {sample_name}\")\n",
    "        plt.tight_layout()\n",
    "        safe_sample = sample_name.replace(\"/\", \"_\")\n",
    "        plt.savefig(f\"{save_folder}/top30_degree_centrality/{safe_sample}.png\", dpi=150)\n",
    "        plt.close()\n",
    "    \n",
    "    # Save combined CSV\n",
    "    if all_top_genes:\n",
    "        combined_df = pd.concat(all_top_genes, ignore_index=True)\n",
    "        combined_df = combined_df[[\"cell_type\", \"sample\", \"rank\", \"gene\", \"degree_centrality_all\"]]\n",
    "        combined_df.to_csv(f\"{save_folder}/top50_degree_centrality_by_sample.csv\", index=False)\n",
    "        print(f\"  \\u2713 Top genes CSV saved\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 11. Heatmap of network scores\n",
    "    # =========================================================\n",
    "    print(f\"\\n[11] Creating heatmap...\")\n",
    "    \n",
    "    N_GENES_HEATMAP = 50\n",
    "    top_genes = set()\n",
    "    for cluster in links.cluster:\n",
    "        cluster_mask = links.merged_score['cluster'] == cluster\n",
    "        cluster_scores = links.merged_score.loc[\n",
    "            cluster_mask, 'degree_centrality_all'\n",
    "        ].sort_values(ascending=False)\n",
    "        top_genes.update(cluster_scores.head(N_GENES_HEATMAP).index)\n",
    "    \n",
    "    score_df = links.merged_score[['cluster', 'degree_centrality_all']].copy()\n",
    "    score_df = score_df[score_df.index.isin(top_genes)]\n",
    "    pivot_table = score_df.pivot(columns='cluster', values='degree_centrality_all')\n",
    "    \n",
    "    plt.figure(figsize=(10, 16))\n",
    "    sns.heatmap(pivot_table, cmap='viridis',\n",
    "                cbar_kws={'label': 'Degree Centrality'},\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    plt.title(f'Network Degree Centrality - {cell_type}\\nTop {N_GENES_HEATMAP} Genes per Sample',\n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Sample', fontsize=12)\n",
    "    plt.ylabel('Gene', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_folder}/network_score_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  \\u2713 Heatmap saved\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 12. Score comparison between samples (WT vs KO)\n",
    "    # =========================================================\n",
    "    print(f\"\\n[12] Score comparison between samples...\")\n",
    "    \n",
    "    if len(links.cluster) >= 2:\n",
    "        CLUSTER1 = links.cluster[0]\n",
    "        CLUSTER2 = links.cluster[1]\n",
    "        print(f\"  Comparing: {CLUSTER1} vs {CLUSTER2}\")\n",
    "        \n",
    "        links.plot_score_comparison_2D(\n",
    "            value=\"degree_centrality_all\",\n",
    "            cluster1=CLUSTER1,\n",
    "            cluster2=CLUSTER2,\n",
    "            percentile=97,\n",
    "            save=f\"{save_folder}/score_comparison\"\n",
    "        )\n",
    "        print(f\"  \\u2713 Comparison plot saved\")\n",
    "    else:\n",
    "        print(f\"  \\u26a0 Only {len(links.cluster)} sample(s) - skipping comparison\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  \\u2713 COMPLETED: {cell_type}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return oracle, links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000013",
   "metadata": {},
   "source": [
    "## 4. Run pipeline for all cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for all cell types\n",
    "results = {}\n",
    "skipped = []\n",
    "\n",
    "for i, cell_type in enumerate(cell_types):\n",
    "    print(f\"\\n\\n>>> [{i+1}/{len(cell_types)}] Starting: {cell_type}\")\n",
    "    \n",
    "    try:\n",
    "        oracle, links = run_celloracle_for_celltype(\n",
    "            adata_full=adata_full,\n",
    "            cell_type=cell_type,\n",
    "            base_GRN=base_GRN,\n",
    "            base_results=base_results,\n",
    "            base_figures=base_figures,\n",
    "            base_genes=base_genes,\n",
    "            min_cells=50,\n",
    "            n_top_genes=3000\n",
    "        )\n",
    "        \n",
    "        if oracle is not None:\n",
    "            results[cell_type] = {'oracle': oracle, 'links': links}\n",
    "        else:\n",
    "            skipped.append(cell_type)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n  ✗ ERROR processing {cell_type}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        skipped.append(cell_type)\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Successfully processed: {len(results)}/{len(cell_types)}\")\n",
    "print(f\"  Completed: {list(results.keys())}\")\n",
    "if skipped:\n",
    "    print(f\"  Skipped/Failed: {skipped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000015",
   "metadata": {},
   "source": [
    "## 5. Cross-cell-type summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined summary of top degree centrality genes across all cell types and samples\n",
    "all_summaries = []\n",
    "\n",
    "for cell_type, res in results.items():\n",
    "    links = res['links']\n",
    "    for sample_name in links.cluster:\n",
    "        df = links.merged_score[links.merged_score['cluster'] == sample_name].copy()\n",
    "        df_top = df.sort_values('degree_centrality_all', ascending=False).head(20)\n",
    "        df_top = df_top[['degree_centrality_all']].copy()\n",
    "        df_top['cell_type'] = cell_type\n",
    "        df_top['sample'] = sample_name\n",
    "        df_top['gene'] = df_top.index\n",
    "        df_top['rank'] = range(1, len(df_top) + 1)\n",
    "        all_summaries.append(df_top)\n",
    "\n",
    "if all_summaries:\n",
    "    summary_df = pd.concat(all_summaries, ignore_index=True)\n",
    "    summary_df = summary_df[['cell_type', 'sample', 'rank', 'gene', 'degree_centrality_all']]\n",
    "    summary_df.to_csv(f\"{base_genes}/cross_celltype_top20_summary.csv\", index=False)\n",
    "    print(f\"\\u2713 Cross-cell-type summary saved\")\n",
    "    print(f\"  Shape: {summary_df.shape}\")\n",
    "    display(summary_df.head(20))\n",
    "else:\n",
    "    print(\"No results to summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: top hub genes across cell types (for a specific sample)\n",
    "if all_summaries:\n",
    "    # Get unique samples\n",
    "    samples = summary_df['sample'].unique()\n",
    "    \n",
    "    for sample_name in samples:\n",
    "        sample_data = summary_df[summary_df['sample'] == sample_name]\n",
    "        pivot = sample_data.pivot_table(\n",
    "            index='gene', columns='cell_type',\n",
    "            values='degree_centrality_all', aggfunc='first'\n",
    "        )\n",
    "        \n",
    "        plt.figure(figsize=(12, max(8, len(pivot) * 0.3)))\n",
    "        sns.heatmap(pivot.fillna(0), cmap='viridis',\n",
    "                    cbar_kws={'label': 'Degree Centrality'},\n",
    "                    linewidths=0.5, linecolor='gray')\n",
    "        plt.title(f'Top Hub Genes Across Cell Types - {sample_name}',\n",
    "                  fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Cell Type', fontsize=12)\n",
    "        plt.ylabel('Gene', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        safe_sample = sample_name.replace(\"/\", \"_\")\n",
    "        plt.savefig(f\"{base_figures}/cross_celltype_heatmap_{safe_sample}.png\",\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"\\u2713 Cross-cell-type heatmap saved for {sample_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ALL DONE ===\")\n",
    "print(f\"\\nResults saved to:\")\n",
    "print(f\"  Oracle/Links objects: {base_results}/\")\n",
    "print(f\"  Figures: {base_figures}/\")\n",
    "print(f\"  Gene lists: {base_genes}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celloracle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}